{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"UTKFace-CNN-race-classifier.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cVDjRXpm2loM"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive/\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ejlOz_423CLS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638986004292,"user_tz":-480,"elapsed":2983,"user":{"displayName":"Tony Hsu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01558143894565572902"}},"outputId":"b272cf3d-f4a9-4fe6-e4a5-ef58754dc3ef"},"source":["import os \n","import tarfile\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","\n","if os.path.exists(\"/content/drive/MyDrive/Colab Notebooks/\"):\n","    COLAB_PATH = \"/content/drive/MyDrive/Colab Notebooks/大伯 - ML_Code\"\n","else:\n","    COLAB_PATH = \"/content/drive/MyDrive/UTKFace-Code/\"\n","os.chdir(COLAB_PATH)\n","\n","!pwd\n","!ls -l"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/UTKFace-Code\n","total 306378\n","-rw------- 1 root root  38599552 Oct 29 08:22 Best_model_params.h5\n","-rw------- 1 root root 167472288 Nov  7 02:03 best_xception_race_weights.h5\n","drwx------ 2 root root      4096 Oct 21 12:21 UTKFace\n","-rw------- 1 root root     34195 Dec  8 17:53 UTKFace-CNN-race-classifier.ipynb\n","drwx------ 2 root root      4096 Oct 21 10:42 UTKFace-data-cleaning\n","drwx------ 2 root root      4096 Oct 22 06:23 UTKFace_data_cleaning_TFRecords\n","drwx------ 2 root root      4096 Oct 12 00:37 UTKFace_not_split_TFRecords\n","-r-------- 1 root root 106634631 Mar 23  2017 UTKFace.tar.gz\n","-rw------- 1 root root    972660 Dec  8 10:33 UTKFace-train_test_split-to-tfrecords.ipynb\n"]}]},{"cell_type":"code","metadata":{"id":"5A-kgDhY585B"},"source":["# Compress {train, test dataset} tfrecords.gz to {train, test} tfrecords.tar\n","# train_path = \"./UTKFace_TFRecords/train/\"\n","# test_path = \"./UTKFace_TFRecords/test/\"\n","\n","# def build_tarfile_to_compress_tfrecords(name, paths):\n","#     for i in range(len(name)):\n","#         with tarfile.open(f\"./UTKFace_TFRecords/{name[i]}/UTKFace_{name[i]}_dataset.tfrecords.tar\", \"w\") as tar:\n","#             path_list = lambda x: os.listdir(x)\n","#             for j in path_list(paths[i]):\n","#                 tar.add(paths[i]+j)\n","\n","# build_tarfile_to_compress_tfrecords((\"train\", \"test\"), (train_path, test_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VF8BQ3Kj3YZ5"},"source":["# Decompress to retrieve train, test dataset tfrecords.gz\n","# tar_paths = \"./UTKFace_TFRecords/\"\n","\n","# def decompress_tarfile_to_retrieve_tfrecords_gz(name, paths):\n","#     for i in range(len(name)):\n","#         with tarfile.open(paths+name[i]+f\"/UTKFace_{name[i]}_dataset.tfrecords.tar\") as tar:\n","#             tar.extractall()\n","\n","# decompress_tarfile_to_retrieve_tfrecords_gz((\"train\", \"test\"), tar_paths)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8LEKxk573kZb"},"source":["# Parse(Preprocess) TFRecord \n","\n","def parse_tfrecord(tfrecord):\n","    feature = {\n","        # \"shape\": tf.io.FixedLenFeature([3], tf.int64),\n","        \"image\": tf.io.FixedLenFeature([], tf.string),\n","        \"label\": tf.io.FixedLenFeature([], tf.int64)\n","    }\n","    parse_example = tf.io.parse_single_example(tfrecord, feature)\n","    image = tf.io.parse_tensor(parse_example[\"image\"], out_type=tf.uint8)\n","    image = tf.reshape(image, shape=[200, 200, 3])\n","\n","    return image, parse_example[\"label\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiSdSSPmgFeH"},"source":["# Preprocess with data augmentation, tf.data pipeline and decompress tfrecords\n","\n","from tensorflow import keras\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import layers, models, callbacks, Model, regularizers\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.xception import preprocess_input, Xception\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","\n","# Data Augmentation use keras ImageDataGenerator\n","# opt1:\n","# data_generator = ImageDataGenerator(\n","#     rotation_range=20,\n","#     width_shift_range=0.2,\n","#     height_shift_range=0.2,\n","#     horizontal_flip=True\n","# )\n","    \n","# data_generator.flow(image, label, batch_size = 32)\n","\n","# opt2:\n","data_augmentation = models.Sequential([\n","    layers.RandomFlip(\"horizontal\"),\n","    layers.RandomRotation(0.1),\n","    layers.RandomZoom(0.1, 0.1)\n","])\n","\n","\n","# Transfer learning\n","def image_preprocess(image, label):\n","    resized_img = tf.image.resize(image, [224, 224])\n","    input_img_resized = preprocess_input(resized_img)\n","\n","    return input_img_resized, label\n","\n","\n","def preprocess_tfrecord(paths, n_threads = AUTOTUNE, compress_attr = \"GZIP\"):\n","    path_list = tf.data.Dataset.list_files(paths, seed = 42)\n","\n","    # decompress tfrecords\n","    dataset = tf.data.TFRecordDataset(path_list, compression_type = compress_attr, num_parallel_reads = n_threads)\n","    dataset = dataset.map(parse_tfrecord, num_parallel_calls = n_threads)\n","\n","    return dataset\n","\n","\n","def OneHotEncode(image, label):\n","    one_hot_label = tf.one_hot(label, len(race_classes))\n","\n","    return image, one_hot_label\n","\n","\n","def preprocess_and_quick_read_dataset(dataset, n_threads = AUTOTUNE, buf_size = None, batch_size = 32, augment = False):\n","    # Zero-Centered - scale: [0~255]->[0~1] (* Don't use Zero-Centered if Transfer Learning)\n","    # dataset = dataset.map(lambda x, y: ((tf.cast(x, dtype = tf.float32) / 255.), y), num_parallel_calls = n_threads)\n","    dataset = dataset.map(lambda x, y: (tf.cast(x, dtype = tf.float32), y), num_parallel_calls = n_threads)\n","    \n","    # Transfer Learning Architecture required img shape\n","    dataset = dataset.map(image_preprocess, num_parallel_calls = n_threads)\n","\n","    # One Hot Encode\n","    dataset = dataset.map(OneHotEncode, num_parallel_calls = n_threads)\n","\n","    dataset = dataset.cache()\n","\n","    # Use Data Augment only on training set\n","    if augment:\n","        dataset = dataset.map(lambda x, y: (data_augmentation(x, training = True), y), num_parallel_calls = n_threads)\n","\n","    if buf_size:\n","        dataset = dataset.shuffle(buf_size)\n","\n","    return dataset.batch(batch_size).prefetch(n_threads)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4Poi-g5F4KAI"},"source":["# Plot UTKFace race img\n","\n","data_clean = False\n","if data_clean:\n","    tfrecords_path = \"UTKFace_data_cleaning_TFRecords/\"\n","else:\n","    tfrecords_path = \"UTKFace_not_split_TFRecords/\"\n","\n","train_paths = os.path.join(tfrecords_path, \"train/UTKFace_train_*.tfrecords.gz\")\n","valid_paths = os.path.join(tfrecords_path, \"valid/UTKFace_valid_*.tfrecords.gz\")\n","test_paths = os.path.join(tfrecords_path, \"test/UTKFace_test_*.tfrecords.gz\")\n","\n","\n","# Race: White, Black, Asia, Indian, Others(Hispanic, Latino, Middle Eastern)\n","race_classes = [\"White\", \"Black\", \"Asia\", \"Indian\", \"Others\"]\n","\n","\n","# UTKFace dataset => train_set: 80%, valid_set: 10%, test_set: 10%  \n","# Batch_size = 32\n","\n","train_set = preprocess_and_quick_read_dataset(preprocess_tfrecord(train_paths), buf_size = 20000 if data_clean else 24000, augment = True)\n","valid_set = preprocess_and_quick_read_dataset(preprocess_tfrecord(valid_paths))\n","test_set = preprocess_and_quick_read_dataset(preprocess_tfrecord(test_paths))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6eq3aUB3XFPT"},"source":["# Check the Y label dimensions\n","# for X, Y in train_set.take(1):\n","#     print(Y.numpy().shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PPRokFI0RMkE"},"source":["# Plot train_set take(1)\n","\n","# plt.figure(figsize = (6, 6), tight_layout = True)\n","# for X, Y in train_set.take(1):\n","#     for i in range(6):\n","#         plt.subplot(3, 3, i+1)\n","#         plt.axis(\"off\")\n","#         plt.imshow(X[i].numpy(), cmap = \"binary\")\n","#         # plt.title(f\"{race_classes[int(Y[i].numpy())]}: ({str(Y[i].numpy())})\", fontsize = 14)\n","        \n","#         # OneHot transform\n","#         plt.title(f\"{race_classes[np.argmax(Y[i])]}: ({np.argmax(Y[i])})\", fontsize = 14)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VCqnB99ZfezL"},"source":["# Plot test_set take(1)\n","\n","# plt.figure(figsize = (6, 6), tight_layout = True)\n","# for X, Y in test_set.take(1):\n","#     for i in range(6):\n","#         plt.subplot(3, 3, i+1)\n","#         plt.axis(\"off\")\n","#         plt.imshow(X[i].numpy(), cmap = \"binary\")\n","#         # plt.title(f\"{race_classes[int(Y[i].numpy())]}: ({str(Y[i].numpy())})\", fontsize = 14)\n","\n","#         # OneHot transform\n","#         plt.title(f\"{race_classes[np.argmax(Y[i])]}: ({np.argmax(Y[i])})\", fontsize = 14)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cz-izk1JDEv3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1638986006566,"user_tz":-480,"elapsed":20,"user":{"displayName":"Tony Hsu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01558143894565572902"}},"outputId":"354a9f67-c168-4831-c321-97705b4b75c4"},"source":["# Golab GPU devices status\n","\n","print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n","!nvidia-smi -L"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Num GPUs Available:  0\n","NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n","\n"]}]},{"cell_type":"code","source":["# Use TPU\n","\n","resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","tf.config.experimental_connect_to_host(resolver.master())\n","tf.tpu.experimental.initialize_tpu_system(resolver)\n","tpu_strategy = tf.distribute.TPUStrategy(resolver)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7evh4ei8BFlb","executionInfo":{"status":"ok","timestamp":1638986790287,"user_tz":-480,"elapsed":13424,"user":{"displayName":"Tony Hsu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01558143894565572902"}},"outputId":"41853d2f-62fc-4667-e9cf-59737c61c34e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n"]},{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:TPU system grpc://10.25.174.130:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:TPU system grpc://10.25.174.130:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.25.174.130:8470\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.25.174.130:8470\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Finished initializing TPU system.\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:Found TPU system:\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"]},{"output_type":"stream","name":"stdout","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]},{"output_type":"stream","name":"stderr","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"]}]},{"cell_type":"code","metadata":{"id":"EFTkYmawsDw1"},"source":["# # CNN Model - VGG16\n","\n","# def vgg16_model(decay = 1e-4):\n","#     model = models.Sequential()\n","    \n","#     # block 1\n","#     model.add(layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizers.L2(decay)\n","#                             , input_shape = (200, 200, 3)))\n","#     model.add(layers.Conv2D(64, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2, 2), strides = 2))\n","    \n","#     # block 2\n","#     model.add(layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Conv2D(128, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2, 2), strides = 2))\n","\n","#     # block 3\n","#     model.add(layers.Conv2D(256, (3, 3), padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Conv2D(256, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Conv2D(256, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2, 2), strides = 2))\n","\n","#     # block 3\n","#     model.add(layers.Conv2D(512, (3, 3), padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Conv2D(512, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Conv2D(512, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2, 2), strides = 2))\n","\n","#     # block 4\n","#     model.add(layers.Conv2D(512, (3, 3), padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Conv2D(512, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Conv2D(512, (3, 3), padding = \"same\", activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2, 2), strides = 2))\n","\n","#     # flatten\n","#     model.add(layers.Flatten())\n","#     model.add(layers.Dense(1024, activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Dropout(0.5))\n","#     # model.add(layers.Dense(4096, activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     # model.add(layers.Dropout(0.5))\n","#     model.add(layers.Dense(512, activation = \"relu\", kernel_regularizer = regularizers.L2(decay)))\n","#     model.add(layers.Dropout(0.5))\n","#     model.add(layers.Dense(len(race_classes), activation = \"softmax\"))\n","\n","#     # compile the model\n","#     opt = tf.keras.optimizers.Adam(learning_rate = 0.001, clipvalue = 0.1)\n","\n","#     model.compile(loss = \"categorical_crossentropy\", optimizer = opt,\n","#                   metrics = [\"accuracy\"])  # OneHotEncode transform -> loss = \"categorical_crossentropy\" \n","    \n","#     return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qXmbMc2w631y"},"source":["# vgg16 = vgg16_model()\n","# vgg16.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rytongRZRo5u"},"source":["# # CNN Model\n","\n","# def cnn_model(lr = 1e-4, epochs = None):\n","\n","#     model = models.Sequential()\n","    \n","#     # step 1:\n","#     model.add(layers.Conv2D(16, (3,3), padding = \"same\", activation = \"relu\", input_shape = (200, 200, 3)))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((3,3)))\n","#     model.add(layers.Dropout(0.25))\n","\n","#     # step 2:\n","#     model.add(layers.Conv2D(32, (3,3), padding = \"same\", activation = \"relu\"))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2,2)))\n","#     model.add(layers.Dropout(0.25))\n","\n","#     # step 3:\n","#     model.add(layers.Conv2D(32, (3,3), padding = \"same\", activation = \"relu\"))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2,2)))\n","#     model.add(layers.Dropout(0.25))\n","\n","#     # step 4:\n","#     model.add(layers.Conv2D(64, (3,3), padding = \"same\", activation = \"relu\"))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.MaxPooling2D((2,2)))\n","#     model.add(layers.Dropout(0.25))\n","\n","#     # flatten\n","#     model.add(layers.Flatten())\n","#     model.add(layers.Dense(128, activation = \"relu\"))\n","#     model.add(layers.BatchNormalization())\n","#     model.add(layers.Dropout(0.5))\n","#     model.add(layers.Dense(len(race_classes), activation = \"softmax\"))\n","\n","#     # compile the model\n","#     opt = tf.keras.optimizers.Adam(learning_rate = lr, clipvalue = 0.1, decay = lr / epochs)\n","#     model.compile(loss = \"categorical_crossentropy\", optimizer = opt,\n","#                 metrics = [\"accuracy\"])  # OneHotEncode transform -> loss = \"categorical_crossentropy\"\n","\n","#     return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NeyxO6IkHLRH"},"source":["# Epochs = 100\n","\n","# cnn = cnn_model(epochs = Epochs)\n","# cnn.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RG7C2eED7oN3"},"source":["# Fit model\n","\n","# Initialize parameters\n","# lr = 1e-4\n","# Batch = 32\n","# Epochs = 100\n","\n","# # the loss remains the same as {Patience} times, early stop will start.\n","# Patience = 15   \n","\n","# cnn = cnn_model(epochs = Epochs)\n","# # cnn.summary()\n","\n","# # cnn: best_race_weights.h5, vgg16: best_vgg16_race_weights.h5\n","# race_classifier_weights = os.path.join(COLAB_PATH, \"best_vgg16_race_weights.h5\")\n","\n","# # Learning scheduling\n","# # performance_scheduler = callbacks.ReduceLROnPlateau(factor = 0.2, patience = 5, min_lr = 1e-6)\n","\n","# check_point = callbacks.ModelCheckpoint(race_classifier_weights, monitor = \"val_loss\", save_best_only = True)\n","# early_stop = callbacks.EarlyStopping(monitor = \"val_loss\", patience = Patience, restore_best_weights = True)\n","\n","# call_backs = [check_point, early_stop]  # performance_scheduler\n","\n","# # model: vgg16, cnn -> 73 epochs, val_acc: ≈77% \n","# history = cnn.fit(train_set,\n","#                   epochs = Epochs,\n","#                 #    steps_per_epoch = 477,\n","#                   validation_data = valid_set,\n","#                 #   initial_epoch = 73,\n","#                 #    validation_steps = 60,\n","#                   callbacks = call_backs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgocZp1EAYRQ"},"source":["# test_loss, test_acc = cnn.evaluate(test_set, verbose = 2)\n","\n","# print(f\"test loss: {test_loss:.4f}\")\n","# print(f\"test acc: {test_acc:.4f}\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HVqUUG4o4VqW"},"source":["# Transfer learning - GPU\n","\n","xception_model = Xception(weights = \"imagenet\",\n","                          include_top = False)\n","gbl_avgpool = layers.GlobalAveragePooling2D()(xception_model.output)\n","output = layers.Dense(len(race_classes), activation = \"softmax\")(gbl_avgpool)\n","model = Model(inputs = xception_model.input, outputs = output)\n","\n","\n","# Xception layers include_top = False, not have last two layers(GlobalAveragePooling2D(), Dense())\n","# for index, layer in enumerate(xception_model.layers):\n","#     print(index, layer.name)\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Transfer learning - TPU strategy\n","\n","# def create_model():\n","#     xception_model = Xception(weights = \"imagenet\",\n","#                               include_top = False)\n","#     gbl_avgpool = layers.GlobalAveragePooling2D()(xception_model.output)\n","#     output = layers.Dense(len(race_classes), activation = \"softmax\")(gbl_avgpool)\n","#     model = Model(inputs = xception_model.input, outputs = output)\n","\n","#     # Freeze xception_model layers weights\n","#     for layer in xception_model.layers:\n","#         layer.trainable = False\n","    \n","#     opt = tf.keras.optimizers.SGD(learning_rate = 0.15, momentum = 0.9, decay = 0.01)    # sgd: 0.03 <= lr <= 0.3\n","#     model.compile(loss = \"categorical_crossentropy\", optimizer = opt, \n","#                   metrics = [\"accuracy\"])\n","    \n","#     return model\n","\n","# with tpu_strategy.scope():\n","#     model = create_model()"],"metadata":{"id":"C4fWMWJ1OCk7"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M3ALFN_sjq92","colab":{"base_uri":"https://localhost:8080/","height":375},"executionInfo":{"status":"error","timestamp":1638986855372,"user_tz":-480,"elapsed":698,"user":{"displayName":"Tony Hsu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01558143894565572902"}},"outputId":"c07d8e9f-8e28-4650-9a88-6778f2fa3d2d"},"source":["# Freeze xception_model layers weights\n","for layer in xception_model.layers:\n","    layer.trainable = False\n","\n","# initialize parameters\n","Epochs = 15\n","\n","\n","# Compile and Fit\n","# SGD:\n","# --- lr: 0.15 -> epoch: 11, val_acc: 0.6791(loss = 0.9065), epoch: 15, val_acc: 0.6728(loss = 0.8944) ----> quick convergence !\n","# --- lr: 0.2 -> epoch: 12, val_acc: 0.6749(loss = 0.9021) ----> quick convergence !\n","# --- lr: 0.3 -> epoch: 12, val_acc: 0.6628(loss = 0.9258)\n","# --- lr: 0.03 -> epoch: 9, val_acc: 0.6560\n","# --- lr: 0.05 -> epoch: 13, val_acc: 0.6529, epoch: 20, val_acc: 0.6628(loss = 0.9678)\n","# opt = tf.keras.optimizers.SGD(learning_rate = 0.15, momentum = 0.9, decay = 0.01)    # sgd: 0.03 <= lr <= 0.3\n","\n","# Adam:\n","opt = tf.keras.optimizers.Adam(learning_rate = 0.001, decay = 0.01)  # Adam not good !\n","\n","\n","model.compile(loss = \"categorical_crossentropy\", optimizer = opt, \n","              metrics = [\"accuracy\"])\n","\n","history = model.fit(train_set, \n","                    epochs = Epochs,\n","                    # steps_per_epoch = int(0.1*594),  \n","                    validation_data = valid_set,\n","                    # validation_steps = int(0.1*75)   \n","                   )"],"execution_count":null,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-aa6d750a33dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0;31m# steps_per_epoch = int(0.1*594),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                     \u001b[0;31m# validation_steps = int(0.1*75)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                    )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1115\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Unable to parse tensor proto"]}]},{"cell_type":"code","metadata":{"id":"vTY29Llwbfbk"},"source":["# EPOCHS = 12\n","\n","# start_lr = 0.00001\n","# min_lr = 0.00001\n","# max_lr = 0.00005  # * tpu_strategy.num_replicas_in_sync\n","# rampup_epochs = 5\n","# sustain_epochs = 0\n","# exp_decay = .8\n","\n","# def lrfn(epoch):\n","#   if epoch < rampup_epochs:\n","#     return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n","#   elif epoch < rampup_epochs + sustain_epochs:\n","#     return max_lr\n","#   else:\n","#     return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n","    \n","# lr_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=True)\n","\n","# rang = np.arange(EPOCHS)\n","# y = [lrfn(x) for x in rang]\n","# plt.plot(rang, y)\n","# print('Learning rate per epoch:')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b2-Ak_T4LTMF","colab":{"base_uri":"https://localhost:8080/","height":837},"executionInfo":{"status":"error","timestamp":1636254241620,"user_tz":-480,"elapsed":6927880,"user":{"displayName":"Tony Hsu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01558143894565572902"}},"outputId":"5508e3a5-dc79-4d02-9360-b24ab0d96452"},"source":["# Unfreeze xception_model layers weights\n","for layer in xception_model.layers:\n","    layer.trainable = True\n","\n","race_classifier_weights = os.path.join(COLAB_PATH, \"best_xception_race_weights.h5\")\n","\n","# initialize parameters\n","# Epochs = 12\n","Patience = 10\n","\n","\n","# Compile and Fit -> learning slow\n","opt = tf.keras.optimizers.SGD(learning_rate = 0.01, momentum = 0.9, \n","                              nesterov = True, decay = 0.001)  \n","model.compile(loss = \"categorical_crossentropy\", optimizer = opt,\n","              metrics = [\"accuracy\"])\n","\n","# Learning scheduling\n","# performance_scheduler = callbacks.ReduceLROnPlateau(factor = 0.5, patience = 2, min_lr = 1e-6)\n","\n","check_point = callbacks.ModelCheckpoint(race_classifier_weights, monitor = \"val_loss\", save_best_only = True)\n","early_stop = callbacks.EarlyStopping(monitor = \"val_loss\", patience = Patience, restore_best_weights = True)\n","\n","call_backs = [check_point, early_stop]  # performance_scheduler\n","\n","history = model.fit(train_set,\n","                     epochs = Epochs,\n","                    #  steps_per_epoch = int(0.75*477),   \n","                     validation_data = valid_set,\n","                    #  validation_steps = int(0.15*75),  \n","                     callbacks = call_backs\n","                   )  "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/12\n","477/477 [==============================] - 819s 1s/step - loss: 0.7748 - accuracy: 0.7240 - val_loss: 0.7875 - val_accuracy: 0.7184\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n","  category=CustomMaskWarning)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/12\n","477/477 [==============================] - 810s 1s/step - loss: 0.5427 - accuracy: 0.8106 - val_loss: 0.5038 - val_accuracy: 0.8222\n","Epoch 3/12\n","477/477 [==============================] - 807s 1s/step - loss: 0.4631 - accuracy: 0.8403 - val_loss: 0.5098 - val_accuracy: 0.8154\n","Epoch 4/12\n","477/477 [==============================] - 806s 1s/step - loss: 0.4035 - accuracy: 0.8635 - val_loss: 0.4698 - val_accuracy: 0.8285\n","Epoch 5/12\n","477/477 [==============================] - 808s 1s/step - loss: 0.3537 - accuracy: 0.8764 - val_loss: 0.5017 - val_accuracy: 0.8228\n","Epoch 6/12\n","477/477 [==============================] - 808s 1s/step - loss: 0.3148 - accuracy: 0.8898 - val_loss: 0.4967 - val_accuracy: 0.8217\n","Epoch 7/12\n","477/477 [==============================] - 807s 1s/step - loss: 0.2678 - accuracy: 0.9079 - val_loss: 0.5098 - val_accuracy: 0.8306\n","Epoch 8/12\n","477/477 [==============================] - 807s 1s/step - loss: 0.2405 - accuracy: 0.9170 - val_loss: 0.5212 - val_accuracy: 0.8338\n"]},{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7f2ea79bbf80>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n","    handle=self._handle, deleter=self._deleter)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n","    _ctx, \"DeleteIterator\", name, handle, deleter)\n","KeyboardInterrupt: \n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/12\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-3a4f3945237c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m                      \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                     \u001b[0;31m#  validation_steps = int(0.15*75),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                      \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_backs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m                    )  \n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"pt7F1qrzHuHs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636254323445,"user_tz":-480,"elapsed":20025,"user":{"displayName":"Tony Hsu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01558143894565572902"}},"outputId":"ff891cfe-a22b-4061-9e6e-ca6dc8218555"},"source":["test_loss, test_acc = model.evaluate(test_set, verbose = 2)\n","\n","print(f\"test loss: {test_loss:.4f}\")\n","print(f\"test acc: {test_acc:.4f}\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["60/60 - 20s - loss: 0.6102 - accuracy: 0.8248\n","test loss: 0.6102\n","test acc: 0.8248\n"]}]},{"cell_type":"code","metadata":{"id":"crzNAiELpjex"},"source":[""],"execution_count":null,"outputs":[]}]}